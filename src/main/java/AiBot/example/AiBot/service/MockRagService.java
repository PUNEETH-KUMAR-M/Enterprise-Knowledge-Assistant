package AiBot.example.AiBot.service;

import org.springframework.context.annotation.Profile;
import org.springframework.stereotype.Service;

import java.util.*;
import java.util.concurrent.ConcurrentHashMap;

@Service
@Profile("dev")
public class MockRagService {

    // In-memory storage for document chunks (simulating vector database)
    private final Map<String, List<String>> documentChunks = new ConcurrentHashMap<>();
    
    // Simple keyword-based search (simulating semantic search)
    private final Map<String, String> documentContents = new ConcurrentHashMap<>();

    public void processDocument(String content, String documentId) {
        // Store full content
        documentContents.put(documentId, content);
        
        // Simple chunking by paragraphs
        String[] chunks = content.split("\n\n");
        List<String> chunkList = new ArrayList<>();
        
        for (String chunk : chunks) {
            chunk = chunk.trim();
            if (!chunk.isEmpty()) {
                chunkList.add(chunk);
            }
        }
        
        documentChunks.put(documentId, chunkList);
        System.out.println("Mock RAG: Processed document " + documentId + " into " + chunkList.size() + " chunks");
    }

    public String askQuestion(String question, String documentId) {
        String content = documentContents.get(documentId);
        if (content == null) {
            return "Document not found.";
        }

        // Simple keyword-based search
        String lowerQuestion = question.toLowerCase();
        String lowerContent = content.toLowerCase();
        
        // Find relevant chunks based on keyword matching
        List<String> relevantChunks = new ArrayList<>();
        List<String> chunks = documentChunks.get(documentId);
        
        if (chunks != null) {
            for (String chunk : chunks) {
                String lowerChunk = chunk.toLowerCase();
                // Check if chunk contains any words from the question
                String[] questionWords = lowerQuestion.split("\\s+");
                for (String word : questionWords) {
                    if (word.length() > 3 && lowerChunk.contains(word)) {
                        relevantChunks.add(chunk);
                        break;
                    }
                }
            }
        }

        // If no relevant chunks found, use the first few paragraphs
        if (relevantChunks.isEmpty() && chunks != null && !chunks.isEmpty()) {
            relevantChunks = chunks.subList(0, Math.min(3, chunks.size()));
        }

        // Generate mock response
        StringBuilder response = new StringBuilder();
        response.append("Based on the document content, here's what I found:\n\n");
        
        if (!relevantChunks.isEmpty()) {
            response.append("Relevant information:\n");
            for (String chunk : relevantChunks) {
                response.append("â€¢ ").append(chunk.substring(0, Math.min(200, chunk.length())));
                if (chunk.length() > 200) response.append("...");
                response.append("\n\n");
            }
        }
        
        response.append("Mock AI Response: This is a simulated response based on the document content. ");
        response.append("In production, this would be generated by OpenAI's GPT model using the retrieved context. ");
        response.append("The question was: \"").append(question).append("\"");
        
        return response.toString();
    }

    public void clearDocuments() {
        documentChunks.clear();
        documentContents.clear();
    }
}
